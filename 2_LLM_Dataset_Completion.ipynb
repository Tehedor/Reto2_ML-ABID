{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69127d82",
   "metadata": {},
   "source": [
    "# 1. Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import spacy\n",
    "# from spacy import displacy\n",
    "\n",
    "import re\n",
    "from multiprocessing import process\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2d083",
   "metadata": {},
   "source": [
    "# 2. Carga del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "url = \"data/train.csv\" \n",
    "df = pd.read_csv(url)\n",
    "df_original = df.copy()\n",
    "\n",
    "url2 = \"formated/train._exportado.csv\" \n",
    "df_formated = pd.read_csv(url)\n",
    "\n",
    "\n",
    "# Test\n",
    "\n",
    "url3 = \"data/test_nolabel.csv\"\n",
    "df_test_original = pd.read_csv(url3)\n",
    "\n",
    "url4 = \"formated/test_exportado.csv\"\n",
    "df_test_formated = pd.read_csv(url4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b52f0",
   "metadata": {},
   "source": [
    "# 3. LLM Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0331547",
   "metadata": {},
   "source": [
    "## 3.1 speaker_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original['speaker_job'] = (\n",
    "    df_original['speaker_job']\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r'\\s+', '_', regex=True)\n",
    ")\n",
    "\n",
    "\n",
    "speaker_job_counts = df_original['speaker_job'].value_counts()\n",
    "top_n = 13\n",
    "frequent_speaker_jobs = set(speaker_job_counts.head(top_n).index)\n",
    "print(f\"Frequent speaker jobs: {frequent_speaker_jobs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc877e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_speaker_job_en = {\n",
    "    \"us_senator\": \"federal_legislator_senate\",\n",
    "    \"president\": \"president\",\n",
    "    \"governor\": \"governor\",\n",
    "    \"us_representative\": \"federal_legislator_house\",\n",
    "    \"president-elect\": \"president\",\n",
    "    \"presidential_candidate\": \"presidential_candidate\",\n",
    "    \"state_senator\": \"state_legislator_senate\",\n",
    "    \"state_representative\": \"state_legislator_house\",\n",
    "    \"former_governor\": \"governor\",\n",
    "    \"senator\": \"federal_legislator_senate\",  # Assuming federal context in absence of \"state\"\n",
    "    \"milwaukee_county_executive\": \"local_executive\",\n",
    "    \"attorney\": \"legal_professional\",\n",
    "    \"us_house_of_representatives\": \"federal_legislator_house\",\n",
    "    \"social_media_posting\": \"public_communicator\",  # Could be refined to \"non_traditional_communicator\" if relevant\n",
    "    \"governor_of_new_jersey\": \"governor\",\n",
    "    \"congressman\": \"federal_legislator_house\",\n",
    "    \"co-host_on_cnn's_\\\"crossfire\\\"\": \"public_communicator\",\n",
    "    \"us_congressman\": \"federal_legislator_house\",\n",
    "    \"congresswoman\": \"federal_legislator_house\",\n",
    "    \"speaker_of_the_house_of_representatives\": \"federal_legislative_leader\",\n",
    "    \"businessman\": \"business_professional\",\n",
    "    \"governor_of_ohio_as_of_jan_10,_2011\": \"governor\",\n",
    "    \"author\": \"public_communicator\",\n",
    "    \"lawyer\": \"legal_professional\",\n",
    "    \"candidate_for_us_senate_and_physician\": \"federal_legislative_candidate\",\n",
    "    \"us_senator_from_ohio\": \"federal_legislator_senate\",\n",
    "    \"lieutenant_governor\": \"state_executive\",\n",
    "    \"house_majority_leader\": \"federal_legislative_leader\",\n",
    "    \"us_representative,_florida_district_23\": \"federal_legislator_house\",\n",
    "    \"consultant\": \"political_advisor\",\n",
    "    \"mayor_of_providence\": \"local_executive\",\n",
    "    \"former_president\": \"president\",\n",
    "    \"columnist\": \"public_communicator\",\n",
    "    \"political_action_committee\": \"political_organization\",\n",
    "    \"radio_host\": \"public_communicator\",\n",
    "    \"madison_school_board_member\": \"local_education_official\",\n",
    "    \"secretary_of_state\": \"state_executive\",\n",
    "    \"attorney_general\": \"state_executive\",\n",
    "    \"us_house_member\": \"federal_legislator_house\",\n",
    "    \"msnbc_host\": \"public_communicator\",\n",
    "    \"senate_democratic_leader\": \"federal_legislative_leader\",\n",
    "    \"senate_minority_leader\": \"federal_legislative_leader\",\n",
    "    \"ohio_treasurer\": \"state_executive\",\n",
    "    \"state_assemblyman\": \"state_legislator_house\",\n",
    "    \"chairman,_republican_national_committee\": \"party_leader\",\n",
    "    \"us_representative,_florida_district_22\": \"federal_legislator_house\",\n",
    "    \"house_minority_leader\": \"federal_legislative_leader\",\n",
    "    \"mayor_of_milwaukee\": \"local_executive\",\n",
    "    \"lieutenant_governor-elect\": \"state_executive\",\n",
    "    \"philanthropist\": \"public_communicator\" # Could be considered \"influencer\" or \"social_actor\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all unique mappings from the dictionary\n",
    "unique_mappings_speaker_job = list(set(mapping_speaker_job_en.values()))\n",
    "print(unique_mappings_speaker_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5627fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('zero-shot-classification', model='roberta-large-mnli')\n",
    "\n",
    "\n",
    "def crear_frase_detallada_speaker_job(row):\n",
    "    partes = [f\"{row['speaker']}\"]\n",
    "    # if pd.notna(row['speaker_job']):\n",
    "    #     partes.append(f\"({row['speaker_job']})\")\n",
    "    if pd.notna(row['state_info']):\n",
    "        partes.append(f\"from {row['state_info']}\")\n",
    "    if pd.notna(row['party_affiliation']):\n",
    "        partes.append(f\"(affiliated with the {row['party_affiliation']} party)\")\n",
    "    partes.append(f\"said: \\\"{row['statement']}\\\"\")\n",
    "    if pd.notna(row['subject']):\n",
    "        partes.append(f\"The statement concerns the topics of: {row['subject']}.\")\n",
    "    return \" \".join(partes)\n",
    "\n",
    "def cliassify_speaker_job(row):\n",
    "    \n",
    "    text = crear_frase_detallada_speaker_job(row)\n",
    "\n",
    "    candidate_labels = unique_mappings_speaker_job\n",
    "\n",
    "    result = classifier(text, candidate_labels)\n",
    "\n",
    "    # Get the label with the highest score\n",
    "    best_label = result['labels'][0]\n",
    "    best_score = result['scores'][0]\n",
    "\n",
    "    if best_score < 0.2:\n",
    "        best_label = \"other\"\n",
    "        best_score = 0.0\n",
    "\n",
    "    return best_label, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df540e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8375748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_original)\n",
    "processes_rows = [] \n",
    "\n",
    "for i in range(n):\n",
    "    if pd.isna(df_original.loc[i, 'speaker_job']) or df_original.loc[i, 'speaker_job'].strip() == \"\":\n",
    "  \n",
    "        classification = cliassify_speaker_job(\n",
    "            df_original.loc[i]\n",
    "        )[0]\n",
    "\n",
    "        df_original.loc[i, 'speaker_job'] = classification\n",
    "\n",
    "        processes_rows.append(i)\n",
    "\n",
    "print(f\"Rows processed: {processes_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cef9aa",
   "metadata": {},
   "source": [
    "## 3.2 state_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_state_info(text):\n",
    "    if isinstance(text, str):  \n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  \n",
    "        return text.strip()  \n",
    "    return text  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original['state_info'] = df_original['state_info'].str.lower()\n",
    "df_original['state_info'] = df_original['state_info'].apply(clean_state_info)\n",
    "state_info_counts = df_original['state_info'].value_counts()\n",
    "\n",
    "top_n = 15\n",
    "frequent_state_info = set(state_info_counts.head(top_n).index)\n",
    "print(f\"Frequent state info: {frequent_state_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc2e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('zero-shot-classification', model='roberta-large-mnli')\n",
    "\n",
    "def crear_frase_detallada_state_info(row):\n",
    "    partes = [f\"{row['speaker']}\"]\n",
    "    if pd.notna(row['speaker_job']):\n",
    "        partes.append(f\"({row['speaker_job']})\")\n",
    "    # if pd.notna(row['state_info']):\n",
    "    #     partes.append(f\"from {row['state_info']}\")\n",
    "    if pd.notna(row['party_affiliation']):\n",
    "        partes.append(f\"(affiliated with the {row['party_affiliation']} party)\")\n",
    "    partes.append(f\"said: \\\"{row['statement']}\\\"\")\n",
    "    if pd.notna(row['subject']):\n",
    "        partes.append(f\"The statement concerns the topics of: {row['subject']}.\")\n",
    "    return \" \".join(partes)\n",
    "\n",
    "\n",
    "\n",
    "def cliassify_state_info(row):\n",
    "    \n",
    "    text = crear_frase_detallada_state_info(row)\n",
    "    print(text)\n",
    "    candidate_labels = list(frequent_state_info)\n",
    "\n",
    "\n",
    "    result = classifier(text, candidate_labels)\n",
    "\n",
    "    best_label = result['labels'][0]\n",
    "    best_score = result['scores'][0]\n",
    "\n",
    "    if best_score < 0.2:\n",
    "        best_label = \"other\"\n",
    "        best_score = 0.0\n",
    "\n",
    "    return best_label, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_original)\n",
    "\n",
    "processed_state_info = df_original['state_info'].copy()\n",
    "\n",
    "processes_rows = []\n",
    "\n",
    "for i in range(n):\n",
    "    if pd.isna(df_original.loc[i, 'state_info']) or df_original.loc[i, 'state_info'].strip() == \"\":\n",
    "        print(f\"Processing row {i} of {n}\")\n",
    "        \n",
    "        # Clasificar el estado\n",
    "        classification = cliassify_state_info(df_original.loc[i])[0]\n",
    "        \n",
    "        # Almacenar el resultado en la lista\n",
    "        processed_state_info[i] = classification\n",
    "        processes_rows.append(i)\n",
    "\n",
    "df_original['state_info'] = processed_state_info\n",
    "\n",
    "df_original['state_info'] = df_original['state_info'].apply(\n",
    "    lambda x: x if x in frequent_state_info else 'other'\n",
    ")\n",
    "\n",
    "print(f\"Rows processed: {processes_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59aea36",
   "metadata": {},
   "source": [
    "## 3.3 party_affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    # Major parties\n",
    "    'republican': 'republican',\n",
    "    'democrat': 'democrat',\n",
    "    'democratic-farmer-labor': 'democrat',\n",
    "\n",
    "    # Independents / None\n",
    "    # 'none': 'independent_None',\n",
    "    'independent': 'independent_None',\n",
    "\n",
    "    # Media\n",
    "    'newsmaker': 'media',\n",
    "    'journalist': 'media',\n",
    "    'columnist': 'media',\n",
    "    'activist': 'media',\n",
    "    'talk-show-host': 'media',\n",
    "    \n",
    "    # Third parties\n",
    "    'libertarian': 'third_Party',\n",
    "    'green': 'third_Party',\n",
    "    'constitution-party': 'third_Party',\n",
    "    'liberal-party-canada': 'third_Party',\n",
    "\n",
    "    # Organizations\n",
    "    'organization': 'organization',\n",
    "    \n",
    "    # Officials  \n",
    "    'state-official': 'official',\n",
    "    'business-leader': 'official',\n",
    "    'labor-leader': 'official',\n",
    "    'education-official': 'official',\n",
    "    'government-body': 'official',\n",
    "\n",
    "    # Tea Party\n",
    "    'tea-party-member': 'republican',\n",
    "    'ocean-state-tea-party-action': 'republican',\n",
    "}\n",
    "\n",
    "def group_party(x):\n",
    "    return mapping.get(x, 'other')  # anything else → 'Other'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all unique mappings from the dictionary\n",
    "unique_mappings_party = list(set(mapping.values()))\n",
    "print(unique_mappings_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('zero-shot-classification', model='roberta-large-mnli')\n",
    "\n",
    "def crear_frase_detallada_party(row):\n",
    "    partes = [f\"{row['speaker']}\"]\n",
    "    if pd.notna(row['speaker_job']):\n",
    "        partes.append(f\"({row['speaker_job']})\")\n",
    "    if pd.notna(row['state_info']):\n",
    "        partes.append(f\"from {row['state_info']}\")\n",
    "    # if pd.notna(row['party_affiliation']) or row['party_affiliation'] != \"none\":\n",
    "    #     partes.append(f\"(affiliated with the {row['party_affiliation']} party)\")\n",
    "    partes.append(f\"said: \\\"{row['statement']}\\\"\")\n",
    "    if pd.notna(row['subject']):\n",
    "        partes.append(f\"The statement concerns the topics of: {row['subject']}.\")\n",
    "    return \" \".join(partes)\n",
    "\n",
    "def cliassify_party_affiliation(row):\n",
    "    \n",
    "    text = crear_frase_detallada_party(row)\n",
    "    candidate_labels = unique_mappings_party\n",
    "\n",
    "    result = classifier(text, candidate_labels)\n",
    "\n",
    "    best_label = result['labels'][0]\n",
    "    best_score = result['scores'][0]\n",
    "\n",
    "    if best_score < 0.2:\n",
    "        best_label = \"other\"\n",
    "        best_score = 0.0\n",
    "\n",
    "    return best_label, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_original)\n",
    "processes_rows = [] \n",
    "\n",
    "for i in range(n):\n",
    "    if pd.isna(df_original.loc[i, 'party_affiliation']) or df_original.loc[i, 'party_affiliation'].strip() == \"\" or df_original.loc[i, 'party_affiliation'] == \"none\":\n",
    "        classification = cliassify_party_affiliation(\n",
    "            df_original.loc[i]\n",
    "        )[0]\n",
    "\n",
    "        df_original.loc[i, 'party_affiliation'] = classification\n",
    "\n",
    "        processes_rows.append(i)\n",
    "    else:\n",
    "        df_original.loc[i, 'party_affiliation'] = group_party(df_original.loc[i, 'party_affiliation'])\n",
    "\n",
    "print(f\"Rows processed: {processes_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c0a0f",
   "metadata": {},
   "source": [
    "# 4. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681ade0",
   "metadata": {},
   "source": [
    "## 4.1 speaker_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad4a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_original['speaker_job'] = (\n",
    "    df_test_original['speaker_job']\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r'\\s+', '_', regex=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffec406",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_test_original)\n",
    "processes_rows = [] \n",
    "\n",
    "for i in range(n):\n",
    "    if pd.isna(df_test_original.loc[i, 'speaker_job']) or df_test_original.loc[i, 'speaker_job'].strip() == \"\":\n",
    "  \n",
    "        classification = cliassify_speaker_job(\n",
    "            df_test_original.loc[i]\n",
    "        )[0]\n",
    "\n",
    "        df_test_original.loc[i, 'speaker_job'] = classification\n",
    "\n",
    "        processes_rows.append(i)\n",
    "\n",
    "print(f\"Rows processed: {processes_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b249486",
   "metadata": {},
   "source": [
    "## 4.2. state_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_original['state_info'] = df_test_original['state_info'].str.lower()\n",
    "df_test_original['state_info'] = df_test_original['state_info'].apply(clean_state_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7cbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_test_original)\n",
    "\n",
    "processed_state_info = df_test_original['state_info'].copy()\n",
    "\n",
    "processes_rows = []\n",
    "\n",
    "for i in range(n):\n",
    "    if pd.isna(df_test_original.loc[i, 'state_info']) or df_test_original.loc[i, 'state_info'].strip() == \"\":\n",
    "        print(f\"Processing row {i} of {n}\")\n",
    "        \n",
    "        # Clasificar el estado\n",
    "        classification = cliassify_state_info(df_test_original.loc[i])[0]\n",
    "        \n",
    "        # Almacenar el resultado en la lista\n",
    "        processed_state_info[i] = classification\n",
    "        processes_rows.append(i)\n",
    "\n",
    "df_test_original['state_info'] = processed_state_info\n",
    "\n",
    "df_test_original['state_info'] = df_test_original['state_info'].apply(\n",
    "    lambda x: x if x in frequent_state_info else 'other'\n",
    ")\n",
    "\n",
    "print(f\"Rows processed: {processes_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62388b11",
   "metadata": {},
   "source": [
    "## 4.3 party_affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f764074",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_test_original)\n",
    "processes_rows = [] \n",
    "\n",
    "for i in range(n):\n",
    "    if pd.isna(df_test_original.loc[i, 'party_affiliation']) or df_test_original.loc[i, 'party_affiliation'].strip() == \"\" or df_original.loc[i, 'party_affiliation'] == \"none\":\n",
    "        classification = cliassify_party_affiliation(\n",
    "            df_test_original.loc[i]\n",
    "        )[0]\n",
    "\n",
    "        df_test_original.loc[i, 'party_affiliation'] = classification\n",
    "\n",
    "        processes_rows.append(i)\n",
    "    else:\n",
    "        df_test_original.loc[i, 'party_affiliation'] = group_party(df_test_original.loc[i, 'party_affiliation'])\n",
    "\n",
    "print(f\"Rows processed: {processes_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8282f53",
   "metadata": {},
   "source": [
    "# 5. Exportar CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1cd454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formated[\"speaker_job-llm\"] = df_original[\"speaker_job\"]\n",
    "df_formated[\"state_info-llm\"] = df_original[\"state_info\"]\n",
    "df_formated[\"party_affiliation-llm\"] = df_original[\"party_affiliation\"]\n",
    "df_test_formated[\"speaker_job-llm\"] = df_test_original[\"speaker_job\"]\n",
    "df_test_formated[\"state_info-llm\"] = df_test_original[\"state_info\"]\n",
    "df_test_formated[\"party_affiliation-llm\"] = df_test_original[\"party_affiliation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5529a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el DataFrame 'dfn' a un archivo CSV\n",
    "df_formated.to_csv('./formated/train_exportado_llm.csv', index=False)\n",
    "\n",
    "df_test_formated.to_csv('./formated/test_exportado_llm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda3_r2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
