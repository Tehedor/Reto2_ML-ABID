{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header style=\"width:100%;position:relative\">\n",
    "  <div style=\"width:80%;float:right;\">\n",
    "    <h1>Challenge Loan Approval Prediction in Pennsylvania</h1>\n",
    "    <h3>Carga y limpieza de los datos</h3>\n",
    "    <h5>Grupo 2</h5>\n",
    "  </div>\n",
    "        <img style=\"width:15%;\" src=\"./images/logo.jpg\" alt=\"UPM\" />\n",
    "</header>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Índice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Importar librerias](#1.-Importar-librerias)  \n",
    "2. [Funciones auxiliares](#2.-Funciones-auxiliares)  \n",
    "3. [Carga del Dataset](#3.-Carga-del-Dataset)  \n",
    "4. [Limpieza de los datos](#4.-Limpieza-de-los-datos)  \n",
    "   * 4.1 [Estudio de las columnas](##4.1-Estudio-de-las-columnas)\n",
    "   * 4.2 [Tratamiento de los duplicados y de los nulos](##4.2-Tratamiento-de-los-duplicados-y-de-los-nulos)\n",
    "   * 4.3 [Tratamiento de las variables categóricas](##4.3-Tratamiento-de-las-variables-categoricas)\n",
    "      * 4.3.1 [Tratamiento de las variables categóricas binarias](###4.3.1-Tratamiento-de-las-variables-categoricas-binarias)\n",
    "      * 4.3.2 [Tratamiento de las variables categóricas no binarias](###4.3.2-Tratamiento-de-las-variables-categoricas-no-binarias)\n",
    "5. [Correlacion](#5.-Correlacion)  \n",
    "6. [Codificacion One-Hot](#6.-Codificacion-One-Hot)  \n",
    "7. [Create Test](#7.-Create-Test)  \n",
    "8. [Exportar CSV](#8.-Exportar-CSV)\n",
    "9. [Referencias](#9.-Referencias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_month(date, mode=0):\n",
    "    if pd.isna(date):\n",
    "        return mode\n",
    "    return datetime.strptime(date, '%d-%b-%y').month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_to_quarter(month):\n",
    "    if month == 0:\n",
    "        return 0\n",
    "    return np.ceil(month / 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_counts(dataframe_function):\n",
    "    \n",
    "    value_counts = dataframe_function.value_counts()\n",
    "    sorted_values = sorted(value_counts.index)\n",
    "    print(\"value_counts\", \", \".join(sorted_values))\n",
    "    print(\"\\nNúmero de apariciones:\\n\", value_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Carga del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"data/train.csv\" \n",
    "data = pd.read_csv(url)\n",
    "df = data.copy()\n",
    "\n",
    "url2 = \"data/test_nolabel.csv\"\n",
    "df_test = pd.read_csv(url2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuramos Pandas para mostrar todas las columnas de un DataFrame al imprimirlo, y luego mostramos las primeras filas del DataFrame df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f884c64a7</td>\n",
       "      <td>1</td>\n",
       "      <td>China is in the South China Sea and (building)...</td>\n",
       "      <td>china,foreign-policy,military</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>President-Elect</td>\n",
       "      <td>New York</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30c2723a188</td>\n",
       "      <td>0</td>\n",
       "      <td>With the resources it takes to execute just ov...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>chris-dodd</td>\n",
       "      <td>U.S. senator</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6936b216e5d</td>\n",
       "      <td>0</td>\n",
       "      <td>The (Wisconsin) governor has proposed tax give...</td>\n",
       "      <td>corporations,pundits,taxes,abc-news-week</td>\n",
       "      <td>donna-brazile</td>\n",
       "      <td>Political commentator</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b5cd9195738</td>\n",
       "      <td>1</td>\n",
       "      <td>Says her representation of an ex-boyfriend who...</td>\n",
       "      <td>candidates-biography,children,ethics,families,...</td>\n",
       "      <td>rebecca-bradley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84f8dac7737</td>\n",
       "      <td>0</td>\n",
       "      <td>At protests in Wisconsin against proposed coll...</td>\n",
       "      <td>health-care,labor,state-budget</td>\n",
       "      <td>republican-party-wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label                                          statement  \\\n",
       "0  81f884c64a7      1  China is in the South China Sea and (building)...   \n",
       "1  30c2723a188      0  With the resources it takes to execute just ov...   \n",
       "2  6936b216e5d      0  The (Wisconsin) governor has proposed tax give...   \n",
       "3  b5cd9195738      1  Says her representation of an ex-boyfriend who...   \n",
       "4  84f8dac7737      0  At protests in Wisconsin against proposed coll...   \n",
       "\n",
       "                                             subject  \\\n",
       "0                      china,foreign-policy,military   \n",
       "1                                        health-care   \n",
       "2           corporations,pundits,taxes,abc-news-week   \n",
       "3  candidates-biography,children,ethics,families,...   \n",
       "4                     health-care,labor,state-budget   \n",
       "\n",
       "                      speaker            speaker_job        state_info  \\\n",
       "0                donald-trump        President-Elect          New York   \n",
       "1                  chris-dodd           U.S. senator       Connecticut   \n",
       "2               donna-brazile  Political commentator  Washington, D.C.   \n",
       "3             rebecca-bradley                    NaN               NaN   \n",
       "4  republican-party-wisconsin                    NaN         Wisconsin   \n",
       "\n",
       "  party_affiliation  \n",
       "0        republican  \n",
       "1          democrat  \n",
       "2          democrat  \n",
       "3              none  \n",
       "4        republican  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con *Info* desplegamos la información del dataframe para saber con que datos trabajaremos en cada una de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                id  label                                          statement  \\\n",
       "0     81f884c64a7      1  China is in the South China Sea and (building)...   \n",
       "1     30c2723a188      0  With the resources it takes to execute just ov...   \n",
       "2     6936b216e5d      0  The (Wisconsin) governor has proposed tax give...   \n",
       "3     b5cd9195738      1  Says her representation of an ex-boyfriend who...   \n",
       "4     84f8dac7737      0  At protests in Wisconsin against proposed coll...   \n",
       "...           ...    ...                                                ...   \n",
       "8945  44edff2b865      1  If Rhode Island does a hybrid [retirement] pla...   \n",
       "8946  4a63b5f9c16      1  The new health care law will force seniors int...   \n",
       "8947  7c57fa8e81c      0  The health insurance plan that (members of Con...   \n",
       "8948  2375e3cf4b7      1  No one in American history has moved from a Ju...   \n",
       "8949  5ae9b14e6e5      0  Says the Army is spending $7 million to sponso...   \n",
       "\n",
       "                                                subject  \\\n",
       "0                         china,foreign-policy,military   \n",
       "1                                           health-care   \n",
       "2              corporations,pundits,taxes,abc-news-week   \n",
       "3     candidates-biography,children,ethics,families,...   \n",
       "4                        health-care,labor,state-budget   \n",
       "...                                                 ...   \n",
       "8945         pensions,public-service,retirement,workers   \n",
       "8946                medicare,message-machine,retirement   \n",
       "8947                                        health-care   \n",
       "8948                                  elections,history   \n",
       "8949                            federal-budget,military   \n",
       "\n",
       "                         speaker                              speaker_job  \\\n",
       "0                   donald-trump                          President-Elect   \n",
       "1                     chris-dodd                             U.S. senator   \n",
       "2                  donna-brazile                    Political commentator   \n",
       "3                rebecca-bradley                                      NaN   \n",
       "4     republican-party-wisconsin                                      NaN   \n",
       "...                          ...                                      ...   \n",
       "8945              lincoln-chafee                                      NaN   \n",
       "8946                   dan-coats                                      NaN   \n",
       "8947           steve-southerland  U.S. Representative, Florida District 2   \n",
       "8948               newt-gingrich             Co-host on CNN's \"Crossfire\"   \n",
       "8949              betty-mccollum                      U.S. Representative   \n",
       "\n",
       "            state_info party_affiliation  \n",
       "0             New York        republican  \n",
       "1          Connecticut          democrat  \n",
       "2     Washington, D.C.          democrat  \n",
       "3                  NaN              none  \n",
       "4            Wisconsin        republican  \n",
       "...                ...               ...  \n",
       "8945      Rhode Island          democrat  \n",
       "8946           Indiana        republican  \n",
       "8947           Florida        republican  \n",
       "8948           Georgia        republican  \n",
       "8949         Minnesota          democrat  \n",
       "\n",
       "[8950 rows x 8 columns]>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a *shape* podemos saber las dimensiones del dataframe, de esta maenra podemos saber la cantidad de filas que tenemos en un incio y la cantidad de columnas con las que trabajaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8950, 8)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización del nombre de todas las columnas para plantear la limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'statement', 'subject', 'speaker', 'speaker_job',\n",
       "       'state_info', 'party_affiliation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Visualización del estadisticos de las columnas numericas para plantear la limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Limpieza de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Estudio de las columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is related to false political claim detection, containing labeled statements (or claims) along with metadata about the speaker, subject, and other contextual information. Below is a detailed breakdown of the dataset's structure and key characteristics:\n",
    "\n",
    "| **Field Name**      | **Data Type** | **Description**                                                                 |\n",
    "|----------------------|---------------|---------------------------------------------------------------------------------|\n",
    "| **id**              | Text          | Unique identifier                                                              |\n",
    "| **label**           | Integer       | Truthfulness score. Binary classification: 1 = true, 0 = false                |\n",
    "| **statement**       | Text          | Text of the claim                                                              |\n",
    "| **subject**         | Text          | Topic of the claim                                                             |\n",
    "| **speaker**         | Text          | Person making the claim                                                        |\n",
    "| **speaker_job**     | Text          | Occupation of the speaker                                                      |\n",
    "| **state_info**      | Text          | Geographic context                                                             |\n",
    "| **party_affiliation** | Text        | Political party of the speaker                                                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de los tipos de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   object\n",
       "label                 int64\n",
       "statement            object\n",
       "subject              object\n",
       "speaker              object\n",
       "speaker_job          object\n",
       "state_info           object\n",
       "party_affiliation    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizacón de valores distintos que tienen cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna: id, Valores distintos: 8950\n",
      "Columna: label, Valores distintos: 2\n",
      "Columna: statement, Valores distintos: 8939\n",
      "Columna: subject, Valores distintos: 3409\n",
      "Columna: speaker, Valores distintos: 2634\n",
      "Columna: speaker_job, Valores distintos: 1090\n",
      "Columna: state_info, Valores distintos: 78\n",
      "Columna: party_affiliation, Valores distintos: 24\n"
     ]
    }
   ],
   "source": [
    "# Obtener el número de valores distintos de cada columna\n",
    "valores_distintos = {columna: df[columna].nunique() for columna in df.columns}\n",
    "\n",
    "# Mostrar el número de valores distintos de cada columna\n",
    "for columna, num_valores in valores_distintos.items():\n",
    "    print(f\"Columna: {columna}, Valores distintos: {num_valores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar id al ser información no necesaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>China is in the South China Sea and (building)...</td>\n",
       "      <td>china,foreign-policy,military</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>President-Elect</td>\n",
       "      <td>New York</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>With the resources it takes to execute just ov...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>chris-dodd</td>\n",
       "      <td>U.S. senator</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The (Wisconsin) governor has proposed tax give...</td>\n",
       "      <td>corporations,pundits,taxes,abc-news-week</td>\n",
       "      <td>donna-brazile</td>\n",
       "      <td>Political commentator</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Says her representation of an ex-boyfriend who...</td>\n",
       "      <td>candidates-biography,children,ethics,families,...</td>\n",
       "      <td>rebecca-bradley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>At protests in Wisconsin against proposed coll...</td>\n",
       "      <td>health-care,labor,state-budget</td>\n",
       "      <td>republican-party-wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          statement  \\\n",
       "0      1  China is in the South China Sea and (building)...   \n",
       "1      0  With the resources it takes to execute just ov...   \n",
       "2      0  The (Wisconsin) governor has proposed tax give...   \n",
       "3      1  Says her representation of an ex-boyfriend who...   \n",
       "4      0  At protests in Wisconsin against proposed coll...   \n",
       "\n",
       "                                             subject  \\\n",
       "0                      china,foreign-policy,military   \n",
       "1                                        health-care   \n",
       "2           corporations,pundits,taxes,abc-news-week   \n",
       "3  candidates-biography,children,ethics,families,...   \n",
       "4                     health-care,labor,state-budget   \n",
       "\n",
       "                      speaker            speaker_job        state_info  \\\n",
       "0                donald-trump        President-Elect          New York   \n",
       "1                  chris-dodd           U.S. senator       Connecticut   \n",
       "2               donna-brazile  Political commentator  Washington, D.C.   \n",
       "3             rebecca-bradley                    NaN               NaN   \n",
       "4  republican-party-wisconsin                    NaN         Wisconsin   \n",
       "\n",
       "  party_affiliation  \n",
       "0        republican  \n",
       "1          democrat  \n",
       "2          democrat  \n",
       "3              none  \n",
       "4        republican  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc = df.drop(columns='id')\n",
    "dfc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Obeservar si el dataset está balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = dfc['label'].value_counts()\n",
    "sns.barplot(x=x.index, y=x.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Está bastante desequilibrado; hay muchos más textos que no son vulos que son vulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Tratamiento de los duplicados y de los nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(dfc.duplicated().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comporbación de si existen nulos y en que columnas se encuentran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                   0\n",
       "statement               0\n",
       "subject                 0\n",
       "speaker                 0\n",
       "speaker_job          2482\n",
       "state_info           1930\n",
       "party_affiliation       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ser demasiados nulos intentaremos sacar la información de otras columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Tratamiento features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Feature Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el conteo de valores únicos de 'speaker'\n",
    "statement_counts = dfc['statement'].value_counts()\n",
    "\n",
    "# Convertir a diccionario\n",
    "statement_counts_dict = statement_counts.to_dict()\n",
    "\n",
    "# Exportar a un archivo JSON\n",
    "with open('json-study-statement/statements.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(statement_counts_dict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poner todas las letras en minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['statement'] = dfc['statement'].str.replace(\"Ill\", \"i'll\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "en_stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "#Collection\n",
    "def create_collection(label):\n",
    "    collection=[]\n",
    "    \n",
    "    for x in dfc[dfc['label']==label]['statement'].str.split():\n",
    "        for i in x:\n",
    "            collection.append(i)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common stopwords in no fake claims, label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Common stopwords in no fake claims, label 0\n",
    "collection=create_collection(0)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "for word in collection: \n",
    "    dic[word]+=1\n",
    "        \n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "\n",
    "x,y=zip(*top)\n",
    "plt.bar(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Common stopwords in fake claims, label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection=create_collection(1)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "for word in collection:\n",
    "    if word in en_stopwords:\n",
    "        dic[word]+=1\n",
    "\n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "\n",
    "x,y=zip(*top)\n",
    "plt.bar(x,y,color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos comprobar que en tanto en fake claims como en no fake claims comparten palabras muy similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrección de negaciones\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"havent\", \"haven't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"hasnt\", \"hasn't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"didnt\", \"didn't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"wont\", \"won't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"wouldnt\", \"wouldn't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"cant\", \"can't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"couldnt\", \"couldn't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"isnt\", \"isn't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"arent\", \"aren't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"shouldnt\", \"shouldn't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"wasnt\", \"wasn't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"werent\", \"weren't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"dont\", \"don't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"doesnt\", \"doesn't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"mightnt\", \"mightn't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"mustnt\", \"mustn't\")\n",
    "# dfc['statement'] = dfc['statement'].str.replace(\"neednt\", \"needn't\")\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# Lista de palabras a reemplazar y sus reemplazos\n",
    "replacements = {\n",
    "    r'\\bim\\b': \"i'm\",\n",
    "    r'\\byoure\\b': \"you're\",\n",
    "    r'\\bhes\\b': \"he's\",\n",
    "    r'\\bshes\\b': \"she's\",\n",
    "    r'\\bits\\b': \"it's\",\n",
    "    r'\\btheyre\\b': \"they're\",\n",
    "    r'\\byoud\\b': \"you'd\",\n",
    "    r'\\bhed\\b': \"he'd\",\n",
    "    r'\\bshed\\b': \"she'd\",\n",
    "    r'\\bwed\\b': \"we'd\",\n",
    "    r'\\btheyd\\b': \"they'd\",\n",
    "    r'\\byoull\\b': \"you'll\",\n",
    "    r'\\bhell\\b': \"he'll\",\n",
    "    r'\\bshell\\b': \"she'll\",\n",
    "    r'\\bitll\\b': \"it'll\",\n",
    "    r'\\bwell\\b': \"we'll\",\n",
    "    r'\\btheyll\\b': \"they'll\",\n",
    "    # hasnt\n",
    "    r'\\bhavent\\b': \"haven't\",\n",
    "    r'\\bhasnt\\b': \"hasn't\",\n",
    "    r'\\bdidnt\\b': \"didn't\",\n",
    "    r'\\bwont\\b': \"won't\",\n",
    "    r'\\bwouldnt\\b': \"wouldn't\",\n",
    "    r'\\bcant\\b': \"can't\",\n",
    "    r'\\bcouldnt\\b': \"couldn't\",\n",
    "    r'\\bisnt\\b': \"isn't\",\n",
    "    r'\\barent\\b': \"aren't\",\n",
    "    r'\\bshouldnt\\b': \"shouldn't\",\n",
    "    r'\\bwasnt\\b': \"wasn't\",\n",
    "    r'\\bwerent\\b': \"weren't\",\n",
    "    r'\\bdont\\b': \"don't\",\n",
    "    r'\\bdoesnt\\b': \"doesn't\",\n",
    "    r'\\bmightnt\\b': \"mightn't\",\n",
    "    r'\\bmustnt\\b': \"mustn't\",\n",
    "    r'\\bneednt\\b': \"needn't\",\n",
    "    r'\\bwhyd\\b': \"why'd\",\n",
    "    r'\\bwholl\\b': \"who'll\",\n",
    "    r'\\bwhod\\b': \"who'd\",\n",
    "    r'\\bwhos\\b': \"who's\",\n",
    "    r'\\bwhats\\b': \"what's\",\n",
    "    r'\\bwhens\\b': \"when's\",\n",
    "    r'\\bwhys\\b': \"why's\",\n",
    "    r'\\bwhereas\\b': \"where's\",\n",
    "    r'\\bwhereve\\b': \"where've\",\n",
    "    r'\\bwhodve\\b': \"who'd've\",\n",
    "    r'\\bwhodnt\\b': \"who'dn't\",\n",
    "    r'\\bwhodve\\b': \"who'd've\",\n",
    "}\n",
    "\n",
    "# Función para aplicar los reemplazos\n",
    "def replace_words(text):\n",
    "    for pattern, replacement in replacements.items():\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "# Aplicar la función a la columna 'statement'\n",
    "dfc['statement'] = dfc['statement'].apply(replace_words)\n",
    "\n",
    "# Verificar el resultado en las primeras filas\n",
    "print(dfc['statement'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_words_by_row = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Contadores globales\n",
    "digit_changes = 0\n",
    "punct_changes = 0\n",
    "url_changes = 0\n",
    "stopword_changes = 0\n",
    "not_changes = 0\n",
    "\n",
    "# Palabras de negación completasstring.punctuation\n",
    "negation_words = {\n",
    "    \"not\", \"never\", \"no\", \"nor\", \"cannot\", \"nobody\", \"none\",\n",
    "    \"nothing\", \"nowhere\", \"neither\", \"can't\", \"dont\", \"won't\", \n",
    "    \"don't\", \"aren't\", \"isn't\", \"wasn't\", \"couldn't\", \n",
    "    \"shouldn't\", \"wouldn't\", \"didn't\", \"hasn't\", \"haven't\", \"hadn't\"\n",
    "}\n",
    "\n",
    "# También detectaremos contracciones con n't\n",
    "negation_suffixes = (\"n't\", \"'t\")\n",
    "\n",
    "def preprocess(text, row_number=None):\n",
    "    global digit_changes, punct_changes, url_changes, stopword_changes, not_changes\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    text = replace_words(text)\n",
    "    # return text\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    oov_tokens = []\n",
    "\n",
    "\n",
    "\n",
    "    for token in doc:\n",
    "        # Eliminar URLs\n",
    "        if token.like_url:\n",
    "            url_changes += 1\n",
    "            continue\n",
    "\n",
    "        # Eliminar números\n",
    "        if token.like_num:\n",
    "            digit_changes += 1\n",
    "            continue\n",
    "        if any(char.isdigit() for char in token.text):\n",
    "            digit_changes += 1\n",
    "            continue\n",
    "\n",
    "        # Eliminar puntuación y espacios\n",
    "        if token.is_punct or token.is_space or token.text in string.punctuation:\n",
    "            if token.is_punct:\n",
    "                punct_changes += 1\n",
    "            continue\n",
    "        if any(char in string.punctuation for char in token.text):\n",
    "            punct_changes += 1\n",
    "            continue\n",
    "\n",
    "        lower_token = token.text.lower()\n",
    "        # Detectar negaciones completas o contracciones\n",
    "        if lower_token == \"wo\":\n",
    "            continue\n",
    "\n",
    "        if lower_token in negation_words or lower_token.endswith(negation_suffixes):\n",
    "            tokens.append(\"not\")\n",
    "            not_changes += 1\n",
    "            continue\n",
    "\n",
    "        # Eliminar stopwords\n",
    "        if token.is_stop or token.text in nlp.Defaults.stop_words or token.text in {'m', 'll', 'd', 're', 's', 've', 't'}:\n",
    "            stopword_changes += 1\n",
    "            continue\n",
    "\n",
    "        if token.is_oov:\n",
    "            oov_tokens.append(token.text)\n",
    "\n",
    "        # Agregar token limpio\n",
    "        tokens.append(token.text)\n",
    "\n",
    "    if row_number is not None and oov_tokens:\n",
    "        oov_words_by_row[row_number] = oov_tokens\n",
    "\n",
    "\n",
    "    clean = ' '.join(tokens)\n",
    "    return clean\n",
    "\n",
    "# ------------------- Sección de pruebas -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # ejemplos = [\n",
    "    #     \"MikeHuckabee.com aren't gets \\\"more hits than virtually any 43 other presidential candidate.\\\"\",\n",
    "    #     \"you can't check out a library book without a photo ID\",\n",
    "    #     \"Visit our site at example.com for more info!\",\n",
    "    #     \"He won't be coming at 5pm.\",negation_words or lower_token.endswith(negation_suffixes):\n",
    "        #     tokens.append(\"not\")\n",
    "        #     continue\n",
    "    #     \"He wouldn't be coming at 5pm.\",\n",
    "    #     \"123 Testing digits and punctuation!!!\",\n",
    "    #     \"Nobody wolda has 2 apples, does he?\"\n",
    "    # ]\n",
    "\n",
    "    ejemplos = [\n",
    "        # \"I'd not check library book photo ID\",\n",
    "        # \"MikeHuckabee.com aren't gets \\\"more hits than virtually any 43 other presidential candidate.\\\"\",\n",
    "        # \"The vast majority of the money I got was from small donors all across the country.''\\tcampaign-finance\\tbarack-obama\\tPresident\\tIllinois\\tdemocrat\\t70\\t71\\t160\\t163\\t9\\tan interview with CNBC's John Harwood \\n5802.json\\ttrue\\tThe Democrat-controlled Senate, it hasnt passed a budget in more than 1,000 days.\\tdeficit,federal-budget,job-accomplishments\\tjohn-boehner\\tSpeaker of the House of Representatives\\tOhio\\trepublican\\t13\\t22\\t11\\t4\\t2\\ta video address\\n6153.json\\thalf-true\\tThe median income in America has dropped by 10 percent in the last four years.\\teconomy,income,jobs\\tmitt-romney\\tFormer governor\\tMassachusetts\\trepublican\\t34\\t32\\t58\\t33\\t19\\ta speech\\n6515.json\\tbarely-true\\tSays U.S. Senate hopeful Tammy Baldwin voted for a $1 trillion stimulus bill that included a wasteful $800,000 to replace light bulbs.\\tenergy,federal-budget,stimulus\\tcrossroads-gps\\tConservative advocacy group\\t\\trepublican\\t9\\t1\\t4\\t1\\t2\\ta television ad\\n385.json\\ttrue\\tSays Clinton did not read the National Intelligence Estimate before voting for the Iraq war.\\tiraq\\tbarack-obama\\tPresident\\tIllinois\\tdemocrat\\t70\\t71\\t160\\t163\\t9\\ta speech in Westerville, Ohio\\n10932.json\\tbarely-true\\tThanks to the Act 10 collective bargaining law that took effect four years ago, ACT scores in Wisconsin are now second-best in the country for states where more than half the kids take the exam.\\teducation,government-regulation,job-accomplishments,labor,unions\\tscott-walker\\tMilwaukee County Executive\\tWisconsin\\trepublican\\t26\\t41\\t32\\t40\\t11\\ta speech\\n5076.json\\tmostly-true\\tOur income, our GDP per capita, is almost 50 percent higher than (it is for) the average European.\\teconomy\\tmitt-romney\\tFormer governor\\tMassachusetts\\trepublican\\t34\\t32\\t58\\t33\\t19\\tan editorial board meeting with an Iowa newspaper\\n12189.json\\thalf-true\\tSays Rick Scott cut Medicaid so people cant get Obamacare.\\thealth-care,medicaid\\trick-scotts-starbucks-heckler\\tActivist, stay-at-home mom\\tFlorida\\tactivist\\t0\\t0\\t2\\t0\\t0\\ta confrontation with Rick Scott at Starbucks\\n945.json\\thalf-true\\tThe stimulus bill includes $8 billion for high-speed rail projects, such as a 'magnetic levitation' line from Las Vegas to Disneyland.\\\"\"\n",
    "        # \"$$23123 $213 hjolas having asdf\",\n",
    "        # 'due', 'latter', 'least', 'these', \"'m\", 'all', 'almost', 'by', 'have', 'he', 'rather', 'without', 'are', 'about', 'were', 'sometimes', 'we', 'still', 'they', 'third', 'none', 'via', 'around', 'yourself', 'full', 'some', '‘ll', 'neither', 'namely', '’d', 'further', 'forty', 'always', 'be', 'anything', 'afterwards', 'therein', 'former', 'others', 'already', 'another', 'a', 'make', 'every', 'so', 'together', 'his', 'beforehand', 'must', 'used', 'for', 'yours', 'themselves', 'with', 'could', 'only', 'fifty', 'beyond', 'per', 'seems', 'regarding', 'six', 'beside', 'nine', 'also', 'nevertheless', 'empty', 'say', 'often', 'meanwhile', 'first', 'how', 'somehow', 'eight', 'anyone', 'therefore', 'does', 'up', 'over', 'sixty', 'it', 'becomes', 'into', 'behind', '‘d', 'once', 'less', 'see', 'what', 'much', 'name', 'her', 'thus', 'itself', 'should', 'you', 'move', 'fifteen', 'myself', 'amongst', 'whether', 'but', 'this', 'eleven', 'out', 'perhaps', 'whatever', 'never', '’m', 'whither', 'to', 'him', 'same', 'whence', 'who', '’ll', 'four', 'its', 'our', 'back', 'thence', 'throughout', 'has', 'that', 'otherwise', 'side', 'after', 'show', 'done', 'few', 'top', 'whereupon', 'yet', 'both', 'three', 'been', 'us', 'me', 'will', 'herself', 'between', 'them', 'thereby', '‘ve', 'either', 'can', \"'ll\", 'next', 'hers', 'those', 'twelve', 'i', 'thru', 'thereupon', 'upon', 'toward', 'himself', 'of', 'seeming', 'though', 'twenty', '’ve', 'n‘t', 'noone', 're', 'something', 'among', 'nowhere', 'wherein', '‘re', 'hundred', 'above', 'ten', 'elsewhere', 'and', 'many', 'my', 'whom', 'as', 'than', 'give', 'under', 'very', 'was', 'indeed', 'anywhere', 'now', 'put', 'hereafter', 'if', 'part', 'against', 'go', 'she', 'mostly', 'through', 'quite', 'doing', 'last', 'hereby', 'which', 'on', 'everything', '‘m', 'wherever', 'along', 'down', 'formerly', 'become', 'why', 'whereby', 'had', 'latterly', 'again', 'below', 'each', 'five', 'several', 'is', 'alone', 'well', 'hereupon', 'whoever', 'else', 'onto', 'no', 'made', 'herein', 'sometime', 'whole', 'own', 'please', 'get', '’re', 'being', 'serious', \"'d\", 'towards', 'even', 'here', 'might', 'mine', 'using', 'ever', 'call', 'there', 'when', 'keep', 'although', 'during', 'moreover', 'your', 'everyone', \"'s\", 'or', 'various', 'until', 'an', 'within', 'bottom', 'becoming', 'whenever', 'whereafter', 'whose', 'anyway', 'nothing', 'at', 'take', \"'re\", 'n’t', 'the', 'not', 'am', 'besides', 'such', 'in', 'unless', 'ourselves', 'nor', 'more', 'most', '’s', 'since', 'seem', \"n't\", 'their', 'one', 'where', 'may', 'amount', 'yourselves', \"'ve\", 'except', 'too', 'everywhere', 'while', 'hence', 'would', 'became', 'really', 'any', 'just', 'thereafter', 'cannot', 'somewhere', 'seemed', 'off', 'from', 'did', 'do', 'anyhow', 'front', 'two', 'enough', 'someone', 'before', 'other', '‘s', 'however', 'across', 'ca', 'then', 'because', 'ours', 'nobody', 'whereas'}\n",
    "        # \"due latter least these 'm all almost by have he rather without are about were sometimes we still they third none via around yourself full some ‘ll neither namely ’d further forty always be anything afterwards therein former others already another a make every so together his beforehand must used for yours themselves with could only fifty beyond per seems regarding six beside nine also nevertheless empty say often meanwhile first how somehow eight anyone therefore does up over sixty it becomes into behind ‘d once less see what much name her thus itself should you move fifteen myself amongst whether but this eleven out perhaps whatever never ’m whither to him same whence who ’ll four its our back thence throughout has that otherwise side after show done few top whereupon yet both three been us me will hersel\"\n",
    "        # \"China is in the South China Sea and (building)a military fortress the likes of which perhaps the  filia world has not seen. \",\n",
    "        \n",
    "        # \"says76 percent voters united states want johnson weld presidential debates\"\n",
    "\n",
    "    ]\n",
    "\n",
    "    for s in ejemplos:\n",
    "        print(f\"Original: {s}\")\n",
    "        resultado = preprocess(s,1)\n",
    "        print(f\"Procesado: {resultado}\\n\")\n",
    "\n",
    "    print(f\"URLs eliminadas: {url_changes}\")\n",
    "    print(f\"Puntuaciónes eliminadas: {punct_changes}\")\n",
    "    print(f\"Stopwords eliminadas: {stopword_changes}\")\n",
    "    print(f\"Dígitos eliminados: {digit_changes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Función para lematizar los verbos en una frase\n",
    "def lemmatize_verbs(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = []\n",
    "    for token in doc:\n",
    "        # Si el token es un verbo, usar su lema; de lo contrario, mantener el texto original\n",
    "        if token.pos_ == \"VERB\":\n",
    "            lemmatized_text.append(token.lemma_)\n",
    "        else:\n",
    "            lemmatized_text.append(token.text)\n",
    "    return \" \".join(lemmatized_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos comprobar no hay una gran diferencia entre ambos tipos de *claims*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# dfc['statement'] = dfc['statement'].apply(lambda x: preprocess(x, row_number=i))\n",
    "dfc['statement'] = dfc.apply(lambda row: preprocess(row['statement'], row.name), axis=1)\n",
    "dfc['statement-raw']  = dfc['statement']\n",
    "dfc['statement-raw'] = dfc['statement-raw'].apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "# Mostrar los contadores\n",
    "print(f\"URLs eliminadas: {url_changes}\")\n",
    "print(f\"Puntuaciones eliminadas: {punct_changes}\")\n",
    "print(f\"Stopwords eliminadas: {stopword_changes}\")\n",
    "print(f\"Dígitos eliminados: {digit_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collection_raw(label):\n",
    "    collection=[]\n",
    "    \n",
    "    for x in dfc[dfc['label']==label]['statement-raw'].str.split():\n",
    "        for i in x:\n",
    "            collection.append(i)\n",
    "    return collection\n",
    "\n",
    "#Common stopwords in no fake claims, label 0\n",
    "collection=create_collection_raw(0)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "for word in collection: \n",
    "    dic[word]+=1\n",
    "        \n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "\n",
    "x,y=zip(*top)\n",
    "plt.bar(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection=create_collection_raw(1)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "for word in collection: \n",
    "    dic[word]+=1\n",
    "        \n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "\n",
    "x,y=zip(*top)\n",
    "plt.bar(x,y, color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lematize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['statement-leamtize'] = dfc['statement'].apply(lambda x: lemmatize_verbs(x))\n",
    "dfc['statement-leamtize'] = dfc['statement-leamtize'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Función para guardar el diccionario en un archivo JSON\n",
    "def save_oov_to_json(oov_dict, output_file=\"./json-study-statement/oov_words_by_row.json\"):\n",
    "    \"\"\"\n",
    "    Guarda el diccionario de palabras fuera del vocabulario (OOV) en un archivo JSON.\n",
    "\n",
    "    :param oov_dict: Diccionario con las palabras OOV por fila.\n",
    "    :param output_file: Nombre del archivo JSON de salida.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(oov_dict, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Diccionario OOV guardado en: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar el archivo JSON: {e}\")\n",
    "\n",
    "# Guardar el diccionario OOV en un archivo JSON\n",
    "\n",
    "save_oov_to_json(oov_words_by_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el conteo de valores únicos de 'speaker'\n",
    "# statement_counts = dfc_backup['statement'].value_counts()\n",
    "statement_counts = dfc['statement-leamtize']\n",
    "\n",
    "# Convertir a diccionario\n",
    "statement_counts_dict = statement_counts.to_dict()\n",
    "\n",
    "# Exportar a un archivo JSON\n",
    "with open('json-study-statement/statements_v1.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(statement_counts_dict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collection_lematize(label):\n",
    "    collection=[]\n",
    "    \n",
    "    for x in dfc[dfc['label']==label]['statement-leamtize'].str.split():\n",
    "        for i in x:\n",
    "            collection.append(i)\n",
    "    return collection\n",
    "\n",
    "#Common stopwords in no fake claims, label 0\n",
    "collection=create_collection_lematize(0)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "for word in collection: \n",
    "    dic[word]+=1\n",
    "        \n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "\n",
    "x,y=zip(*top)\n",
    "plt.bar(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection=create_collection_lematize(1)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "for word in collection:\n",
    "    if word in en_stopwords:\n",
    "        dic[word]+=1\n",
    "\n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "\n",
    "x,y=zip(*top)\n",
    "plt.bar(x,y,color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.head()\n",
    "\n",
    "# dfc.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Resto de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfc = df.copy()\n",
    "\n",
    "# dfc['subject'].value_counts()\n",
    "\n",
    "dfc['subject'].iloc[1:10]                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['subject'] = dfc['subject'].str.lower()\n",
    "dfc['subject_list'] = (\n",
    "    dfc['subject']\n",
    "    .str.split(',')\n",
    "    .apply(lambda lst: [s.strip() for s in lst if s.strip()])\n",
    ")\n",
    "\n",
    "# 3. “Explode” para tener una fila por cada etiqueta y contar\n",
    "subjects_exploded = dfc.explode('subject_list')\n",
    "subject_counts = subjects_exploded['subject_list'].value_counts()\n",
    "print(subject_counts)\n",
    "# 4. Convertir a diccionario\n",
    "subject_count_dict = subject_counts.to_dict()\n",
    "with open('json-study/subject_counts.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(subject_count_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# dfc['subject_list'].iloc[1:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### maping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_mapping = {\n",
    "    # economia_y_finanzas\n",
    "    \"economy\": \"subject-economia_y_finanzas\",\n",
    "    \"taxes\": \"subject-economia_y_finanzas\",\n",
    "    \"federal-budget\": \"subject-economia_y_finanzas\",\n",
    "    \"state-budget\": \"subject-economia_y_finanzas\",\n",
    "    \"income\": \"subject-economia_y_finanzas\",\n",
    "    \"debt\": \"subject-economia_y_finanzas\",\n",
    "    \"deficit\": \"subject-economia_y_finanzas\",\n",
    "    \"market-regulation\": \"subject-economia_y_finanzas\",\n",
    "    \"corporations\": \"subject-economia_y_finanzas\",\n",
    "    \"stimulus\": \"subject-economia_y_finanzas\",\n",
    "    \"small-business\": \"subject-economia_y_finanzas\",\n",
    "    \"bankruptcy\": \"subject-economia_y_finanzas\",\n",
    "    \"government-regulation\": \"subject-economia_y_finanzas\",\n",
    "    \"financial-regulation\": \"subject-economia_y_finanzas\",\n",
    "    \"housing\": \"subject-economia_y_finanzas\",\n",
    "    \"agriculture\": \"subject-economia_y_finanzas\",\n",
    "    \"poverty\": \"subject-economia_y_finanzas\",\n",
    "    \"retirement\": \"subject-economia_y_finanzas\",\n",
    "    \"pensions\": \"subject-economia_y_finanzas\",\n",
    "\n",
    "    # salud_y_bienestar\n",
    "    \"health-care\": \"subject-salud_y_bienestar\",\n",
    "    \"medicare\": \"subject-salud_y_bienestar\",\n",
    "    \"medicaid\": \"subject-salud_y_bienestar\",\n",
    "    \"public-health\": \"subject-salud_y_bienestar\",\n",
    "    \"disability\": \"subject-salud_y_bienestar\",\n",
    "    \"drugs\": \"subject-salud_y_bienestar\",\n",
    "    \"abortion\": \"subject-salud_y_bienestar\",\n",
    "    \"hunger\": \"subject-salud_y_bienestar\",\n",
    "    \"ebola\": \"subject-salud_y_bienestar\",\n",
    "    \"autism\": \"subject-salud_y_bienestar\",\n",
    "    \"marijuana\": \"subject-salud_y_bienestar\",\n",
    "    \"welfare\": \"subject-salud_y_bienestar\",\n",
    "\n",
    "    # Educación\n",
    "    \"education\": \"subject-educacion\",\n",
    "    \"children\": \"subject-educacion\",\n",
    "\n",
    "    # trabajo_y_empleo\n",
    "    \"jobs\": \"subject-trabajo_y_empleo\",\n",
    "    \"labor\": \"subject-trabajo_y_empleo\",\n",
    "    \"workers\": \"subject-trabajo_y_empleo\",\n",
    "    \"unions\": \"subject-trabajo_y_empleo\",\n",
    "    \"job-accomplishments\": \"subject-trabajo_y_empleo\",\n",
    "\n",
    "    # Política y Gobierno\n",
    "    \"elections\": \"subject-politica_y_gobierno\",\n",
    "    \"candidates-biography\": \"subject-politica_y_gobierno\",\n",
    "    \"congress\": \"subject-politica_y_gobierno\",\n",
    "    \"state-finances\": \"subject-politica_y_gobierno\",\n",
    "    \"city-government\": \"subject-politica_y_gobierno\",\n",
    "    \"county-government\": \"subject-politica_y_gobierno\",\n",
    "    \"campaign-finance\": \"subject-politica_y_gobierno\",\n",
    "    \"voting-record\": \"subject-politica_y_gobierno\",\n",
    "    \"transparency\": \"subject-politica_y_gobierno\",\n",
    "    \"debates\": \"subject-politica_y_gobierno\",\n",
    "    \"redistricting\": \"subject-politica_y_gobierno\",\n",
    "    \"congressional-rules\": \"subject-politica_y_gobierno\",\n",
    "    \"polls\": \"subject-politica_y_gobierno\",\n",
    "    \"government-efficiency\": \"subject-politica_y_gobierno\",\n",
    "    \"campaign-advertising\": \"subject-politica_y_gobierno\",\n",
    "    \"bipartisanship\": \"subject-politica_y_gobierno\",\n",
    "    \"infrastructure\": \"subject-politica_y_gobierno\",\n",
    "    \"transportation\": \"subject-politica_y_gobierno\",\n",
    "    \"message-machine\": \"subject-politica_y_gobierno\",\n",
    "    \"message-machine-2012\": \"subject-politica_y_gobierno\",\n",
    "    \"message-machine-2014\": \"subject-politica_y_gobierno\",\n",
    "    \"states\": \"subject-politica_y_gobierno\",\n",
    "\n",
    "    # Seguridad y Justicia\n",
    "    \"crime\": \"subject-seguridad_y_justicia\",\n",
    "    \"criminal-justice\": \"subject-seguridad_y_justicia\",\n",
    "    \"legal-issues\": \"subject-seguridad_y_justicia\",\n",
    "    \"public-safety\": \"subject-seguridad_y_justicia\",\n",
    "    \"death-penalty\": \"subject-seguridad_y_justicia\",\n",
    "    \"terrorism\": \"subject-seguridad_y_justicia\",\n",
    "    \"homeland-security\": \"subject-seguridad_y_justicia\",\n",
    "    \"supreme-court\": \"subject-seguridad_y_justicia\",\n",
    "    \"consumer-safety\": \"subject-seguridad_y_justicia\",\n",
    "    \"privacy\": \"subject-seguridad_y_justicia\",\n",
    "    \"guns\": \"subject-seguridad_y_justicia\",\n",
    "    \"social-security\": \"subject-seguridad_y_justicia\",\n",
    "\n",
    "    # Relaciones Internacionales\n",
    "    \"foreign-policy\": \"subject-relaciones_internacionales\",\n",
    "    \"military\": \"subject-relaciones_internacionales\",\n",
    "    \"iraq\": \"subject-relaciones_internacionales\",\n",
    "    \"afghanistan\": \"subject-relaciones_internacionales\",\n",
    "    \"china\": \"subject-relaciones_internacionales\",\n",
    "    \"israel\": \"subject-relaciones_internacionales\",\n",
    "    \"trade\": \"subject-relaciones_internacionales\",\n",
    "    \"nuclear\": \"subject-relaciones_internacionales\",\n",
    "    \"islam\": \"subject-relaciones_internacionales\",\n",
    "\n",
    "    # Medio Ambiente y Energía\n",
    "    \"energy\": \"subject-medio_ambiente_y_energia\",\n",
    "    \"climate-change\": \"subject-medio_ambiente_y_energia\",\n",
    "    \"oil-spill\": \"subject-medio_ambiente_y_energia\",\n",
    "    \"environment\": \"subject-medio_ambiente_y_energia\",\n",
    "    \"water\": \"subject-medio_ambiente_y_energia\",\n",
    "    \"cap-and-trade\": \"subject-medio_ambiente_y_energia\",\n",
    "    \"natural-disasters\": \"subject-medio_ambiente_y_energia\",\n",
    "\n",
    "    # Sociedad y Cultura\n",
    "    \"religion\": \"subject-sociedad_y_cultura\",\n",
    "    \"gays-and-lesbians\": \"subject-sociedad_y_cultura\",\n",
    "    \"women\": \"subject-sociedad_y_cultura\",\n",
    "    \"families\": \"subject-sociedad_y_cultura\",\n",
    "    \"marriage\": \"subject-sociedad_y_cultura\",\n",
    "    \"civil-rights\": \"subject-sociedad_y_cultura\",\n",
    "    \"immigration\": \"subject-sociedad_y_cultura\",\n",
    "    \"diversity\": \"subject-sociedad_y_cultura\",\n",
    "    \"sexuality\": \"subject-sociedad_y_cultura\",\n",
    "    \"ethics\": \"subject-sociedad_y_cultura\",\n",
    "    \"history\": \"subject-sociedad_y_cultura\",\n",
    "    \"pundits\": \"subject-sociedad_y_cultura\",\n",
    "    \"human-rights\": \"subject-sociedad_y_cultura\",\n",
    "    \"pop-culture\": \"subject-sociedad_y_cultura\",\n",
    "    \"colbert-report\": \"subject-sociedad_y_cultura\",\n",
    "    \"population\": \"subject-sociedad_y_cultura\",\n",
    "\n",
    "    # Ciencia y Tecnología\n",
    "    \"science\": \"subject-ciencia_y_tecnologia\",\n",
    "    \"space\": \"subject-ciencia_y_tecnologia\",\n",
    "\n",
    "    # Otros / Misceláneos\n",
    "    \"sports\": \"subject-otros\",\n",
    "    \"fake-news\": \"subject-otros\",\n",
    "    \"food\": \"subject-otros\",\n",
    "    \"baseball\": \"subject-otros\",\n",
    "    \"recreation\": \"subject-otros\",\n",
    "    \"weather\": \"subject-otros\",\n",
    "    \"food-safety\": \"subject-otros\",\n",
    "    \"patriotism\": \"subject-otros\",\n",
    "    \"nightlife\": \"subject-otros\",\n",
    "    \"lottery\": \"subject-otros\",\n",
    "    \"after-the-fact\": \"subject-otros\",\n",
    "    \"urban\": \"subject-otros\",\n",
    "    \"animals\": \"subject-otros\",\n",
    "    \"gambling\": \"subject-otros\",\n",
    "    \"alcohol\": \"subject-otros\",\n",
    "    \"tourism\": \"subject-otros\",\n",
    "    \"census\": \"subject-otros\",\n",
    "    \"homeless\": \"subject-otros\",\n",
    "    \"veterans\": \"subject-otros\",\n",
    "    \"wealth\": \"subject-otros\",\n",
    "    \"county-budget\": \"subject-otros\",\n",
    "    \"city-budget\": \"subject-otros\",\n",
    "    \"new-hampshire-2012\": \"subject-otros\",\n",
    "    \"sotomayor-nomination\": \"subject-otros\",\n",
    "    \"kagan-nomination\": \"subject-otros\",\n",
    "    \"occupy-wall-street\": \"subject-otros\",\n",
    "    \"florida\": \"subject-otros\",\n",
    "    \"florida-amendments\": \"subject-otros\",\n",
    "    \"public-service\": \"subject-otros\",\n",
    "    \"gas-prices\": \"subject-otros\",\n",
    "    \"bush-administration\": \"subject-otros\",\n",
    "    \"obama-birth-certificate\": \"subject-otros\",\n",
    "    \"10-news-tampa-bay\": \"subject-otros\",\n",
    "    \"abc-news-week\": \"subject-otros\",\n",
    "    \"corrections-and-updates\": \"subject-otros\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos el mapeo al DataFrame\n",
    "subjects_exploded['subject_category'] = subjects_exploded['subject_list'].map(subject_mapping).fillna('subject-otros')\n",
    "\n",
    "# Obtenemos los conteos por nueva categoría\n",
    "category_counts = subjects_exploded['subject_category'].value_counts()\n",
    "\n",
    "print(category_counts)\n",
    "subjects_exploded['subject_category'].iloc[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a cortar el diccionario por el 1% de los datos para evitar posible overfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage = 0.01\n",
    "# num_filas = dfc.shape[0]\n",
    "# cut_count_namber = int(num_filas * percentage)\n",
    "# print(\"Número de filas para el corte:\", cut_count_namber)\n",
    "\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# df2 = dfc.copy()\n",
    "\n",
    "# frequent_subjects = set(subject_counts[subject_counts >= cut_count_namber].index)\n",
    "\n",
    "# # Sustituir las etiquetas raras por 'other_subject'\n",
    "# df2['subject_list_clean'] = df2['subject_list'].apply(\n",
    "#     lambda lst: [s if s in frequent_subjects else 'other_topics' for s in lst]\n",
    "# )\n",
    "\n",
    "# # Binariza con MultiLabelBinarizer\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# onehot = mlb.fit_transform(df2['subject_list_clean'])\n",
    "\n",
    "# # DataFrame de one-hot y concatenación\n",
    "# df_subjects_onehot = pd.DataFrame(\n",
    "#     onehot,\n",
    "#     columns=mlb.classes_,\n",
    "#     index=df2.index\n",
    "# )\n",
    "\n",
    "# df2 = pd.concat([df2, df_subjects_onehot], axis=1)\n",
    "\n",
    "# # df2.head()\n",
    "# df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "# --- 2) Mapea cada subject a su categoría y quita duplicados ---\n",
    "dfc['subject_categories'] = dfc['subject_list'].apply(\n",
    "    lambda lst: list({\n",
    "        subject_mapping.get(s, 'subject-otros') \n",
    "        for s in lst\n",
    "    })\n",
    ")\n",
    "\n",
    "# (Opcional) echa un vistazo:\n",
    "print(dfc[['subject_list','subject_categories']].head())\n",
    "\n",
    "# --- 3) One-Hot Binarizer sobre la lista de categorías ---\n",
    "mlb = MultiLabelBinarizer()\n",
    "onehot = mlb.fit_transform(dfc['subject_categories'])\n",
    "\n",
    "# Construye el DataFrame de one-hot\n",
    "df_onehot = pd.DataFrame(\n",
    "    onehot,\n",
    "    columns=mlb.classes_,\n",
    "    index=dfc.index\n",
    ")\n",
    "\n",
    "\n",
    "dfc = pd.concat([dfc, df_onehot], axis=1)\n",
    "\n",
    "print(dfc.shape)\n",
    "dfc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.drop(columns='subject', inplace=True)\n",
    "dfc.drop(columns='subject_list', inplace=True)\n",
    "dfc.drop(columns='subject_categories', inplace=True)\n",
    "\n",
    "print(dfc.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el conteo de valores únicos de 'speaker'\n",
    "speaker_counts = dfc['speaker'].value_counts()\n",
    "speaker_counts_test = df_test['speaker'].value_counts()\n",
    "\n",
    "# Convertir a diccionario\n",
    "speaker_counts_dict = speaker_counts.to_dict()\n",
    "speaker_counts_test_dict = speaker_counts_test.to_dict()\n",
    "\n",
    "# Exportar a un archivo JSON\n",
    "with open('json-study/speaker_counts.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(speaker_counts_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open('json-study/speaker_counts_test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(speaker_counts_test_dict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando los archivos JSON json-study/speaker_counts_test.json y json-study/speaker_counts_test.json, que contienen los conteos de apariciones de cada speaker tanto en el conjunto de entrenamiento como en el de prueba, se ha obtenido la lista de los 20 speakers más frecuentes en el conjunto de prueba.\n",
    "\n",
    "Al analizar dicha lista, se observa que a partir del décimo speaker se produce una disminución significativa en la frecuencia de aparición. Por tanto, este punto podría considerarse un umbral razonable para realizar un corte: mantener los 10 speakers más frecuentes como categorías individuales y agrupar el resto bajo una categoría común, como \"other_speakers\". Esta decisión busca reducir el riesgo de overfitting y mejorar la capacidad de generalización del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "| ID  | Name               | dfc | df_test |\n",
    "|-----|--------------------|-----|---------|\n",
    "| 1   | barack-obama       | 435 | 176     |\n",
    "| 2   | donald-trump       | 247 | 96      |\n",
    "| 3   | hillary-clinton    | 204 | 93      |\n",
    "| 4   | mitt-romney        | 142 | 70      |\n",
    "| 5   | john-mccain        | 139 | 50      |\n",
    "| 6   | chain-email        | 128 | 50      |\n",
    "| 7   | scott-walker       | 123 | 60      |\n",
    "| 8   | rick-perry         | 117 | 56      |\n",
    "| 9   | rick-scott         | 105 | 45      |\n",
    "| 10  | marco-rubio        | 99  | 54      |\n",
    "| 11  | ted-cruz           | 82  | 36      |\n",
    "| 12  | bernie-s           | 75  | 31      |\n",
    "| 13  | facebook-posts     | 75  | 25      |\n",
    "| 14  | chris-christie     | 74  | 30      |\n",
    "| 15  | charlie-crist      | 62  | 28      |\n",
    "| 16  | newt-gingrich      | 62  | 21      |\n",
    "| 17  | jeb-bush           | 60  | 19      |\n",
    "| 18  | blog-posting       | 57  | 24      |\n",
    "| 19  | joe-biden          | 54  | 22      |\n",
    "| 20  | paul-ryan          | 50  | 20      |\n",
    "\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos por donde cortar\n",
    "top_n = 10\n",
    "frequent_speakers = set(speaker_counts.head(top_n).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Agrupar los menos frecuentes como 'other_speakers'\n",
    "dfc['speaker_grouped'] = dfc['speaker'].apply(\n",
    "    lambda s: s if s in frequent_speakers else 'other_speakers'\n",
    ")\n",
    "\n",
    "dfc['speaker_grouped'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.drop(columns='speaker', inplace=True)\n",
    "dfc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - speaker_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['speaker_job'] = (\n",
    "    dfc['speaker_job']\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r'\\s+', '_', regex=True)\n",
    ")\n",
    "\n",
    "# Obtener el conteo de valores únicos de 'speaker'\n",
    "speaker_job_counts = dfc['speaker_job'].value_counts()\n",
    "speaker_job_counts_test = df_test['speaker_job'].value_counts()\n",
    "\n",
    "\n",
    "# Convertir a diccionario\n",
    "speaker_job_counts_dict = speaker_job_counts.to_dict()\n",
    "speaker_job_counts_test_dict = speaker_job_counts_test.to_dict()\n",
    "\n",
    "# Exportar a un archivo JSON\n",
    "with open('json-study/speaker_job_counts.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(speaker_job_counts_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open('json-study/speaker_job_counts_test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(speaker_job_counts_test_dict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando los archivos JSON json-study/speaker__job_counts_test.json y json-study/speaker_job_counts_test.json, que contienen los conteos de apariciones de cada speaker_job tanto en el conjunto de entrenamiento como en el de prueba, se ha obtenido la lista de los 20 speakers_jobs más frecuentes en el conjunto de prueba.\n",
    "\n",
    "Al analizar dicha lista, se observa que a partir del treceavo speaker_job se produce una disminución significativa en la frecuencia de aparición. Por tanto, este punto podría considerarse un umbral razonable para realizar un corte: mantener los 13 speakers_jobs más frecuentes como categorías individuales y agrupar el resto bajo una categoría común, como \"other_speakers_job\". Esta decisión busca reducir el riesgo de overfitting y mejorar la capacidad de generalización del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "| id  | speaker_job                                | train_count | test_count |\n",
    "|-----|--------------------------------------------|-------------|------------|\n",
    "| 1   | u_s__senator                               | 627         | 204        |\n",
    "| 2   | president                                  | 438         | 177        |\n",
    "| 3   | governor                                   | 368         | 152        |\n",
    "| 4   | u_s__representative                        | 260         | 61         |\n",
    "| 5   | president-elect                            | 247         | 96         |\n",
    "| 6   | presidential_candidate                     | 216         | 99         |\n",
    "| 7   | state_senator                              | 186         | 36         |\n",
    "| 8   | state_representative                       | 155         | 30         |\n",
    "| 9   | former_governor                            | 143         | 70         |\n",
    "| 10  | senator                                    | 129         | 64         |\n",
    "| 11  | milwaukee_county_executive                 | 123         | 60         |\n",
    "| 12  | attorney                                   | 94          | 32         |\n",
    "| 13  | u_s__house_of_representatives              | 81          | 37         |\n",
    "| 14  | social_media_posting                       | 75          | 25         |\n",
    "| 15  | governor_of_new_jersey                     | 74          | 30         |\n",
    "| 16  | congressman                                | 70          | 38         |\n",
    "| 17  | co-host_on_cnn_s__crossfire                | 66          | 22         |\n",
    "| 18  | u_s__congressman                           | 56          | 26         |\n",
    "| 19  | speaker_of_the_house_of_representatives    | 49          | 23         |\n",
    "| 20  | congresswoman                              | 49          | 18         |\n",
    "\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir el punto de corte (por ejemplo, los 10 más frecuentes)\n",
    "top_n = 13\n",
    "frequent_speaker_jobs = set(speaker_job_counts.head(top_n).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los menos frecuentes como 'other_speaker_jobs'\n",
    "dfc['speaker_job_grouped'] = dfc['speaker_job'].apply(\n",
    "    lambda job: job if job in frequent_speaker_jobs else 'other_speaker_jobs'\n",
    ")\n",
    "\n",
    "# Ver el resultado final\n",
    "dfc['speaker_job_grouped'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.drop(columns='speaker_job', inplace=True)\n",
    "dfc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - state_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el conteo de valores únicos de 'speaker'\n",
    "state_info_counts = dfc['state_info'].value_counts()\n",
    "state_info_counts_test = df_test['state_info'].value_counts()\n",
    "\n",
    "\n",
    "# Convertir a diccionario\n",
    "state_info_counts_dict = state_info_counts.to_dict()\n",
    "state_info_counts_test_dict = state_info_counts_test.to_dict()\n",
    "\n",
    "# Exportar a un archivo JSON\n",
    "with open('json-study/state_info_counts.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(state_info_counts_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open('json-study/state_info_counts_test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(state_info_counts_test_dict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Número | Estado               | Train | Test |\n",
    "|--------|----------------------|-------|------|\n",
    "| 1      | Texas                | 879   | 380  |\n",
    "| 2      | Florida              | 853   | 378  |\n",
    "| 3      | Wisconsin            | 648   | 252  |\n",
    "| 4      | New York             | 579   | 250  |\n",
    "| 5      | Illinois             | 487   | 205  |\n",
    "| 6      | Ohio                 | 408   | 178  |\n",
    "| 7      | Georgia              | 381   | 164  |\n",
    "| 8      | Virginia             | 368   | 144  |\n",
    "| 9      | Rhode Island         | 317   | 135  |\n",
    "| 10     | New Jersey           | 209   | 96   |\n",
    "| 11     | Oregon               | 220   | 87   |\n",
    "| 12     | Massachusetts        | 167   | 83   |\n",
    "| 13     | Arizona              | 160   | 68   |\n",
    "| 14     | California           | 121   | 59   |\n",
    "| 15     | Washington, D.C.     | 89    | 52   |\n",
    "| 16     | Vermont              | 80    | 37   |\n",
    "| 17     | New Hampshire        | 79    | 28   |\n",
    "| 18     | Pennsylvania         | 79    | 33   |\n",
    "| 19     | Arkansas             | 77    | 26   |\n",
    "| 20     | Kentucky             | 72    | 26   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando los archivos JSON json-study/state_info_counts_test.json y json-study/state_info_counts.json, que contienen los conteos de apariciones de cada estado tanto en el conjunto de entrenamiento como en el de prueba, se ha obtenido la lista de los 20 estados más frecuentes en el conjunto de prueba.\n",
    "\n",
    "Al analizar dicha lista, se observa que a partir del quinceavo estado se produce una disminución significativa en la frecuencia de aparición. Por tanto, este punto podría considerarse un umbral razonable para realizar un corte: mantener los 15 estados más frecuentes como categorías individuales y agrupar el resto bajo una categoría común, como \"other_states\". Esta decisión busca reducir el riesgo de overfitting y mejorar la capacidad de generalización del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el conteo de valores únicos de 'state_info'\n",
    "state_info_counts = dfc['state_info'].value_counts()\n",
    "\n",
    "# Elegir el punto de corte (por ejemplo, los 10 más frecuentes)\n",
    "top_n = 15\n",
    "frequent_state_info = set(state_info_counts.head(top_n).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los menos frecuentes como 'other_state_info'\n",
    "dfc['state_info_grouped'] = dfc['state_info'].apply(\n",
    "    lambda info: info if info in frequent_state_info else 'other_state_info'\n",
    ")\n",
    "\n",
    "# 6. Ver el resultado final\n",
    "dfc['state_info_grouped'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.drop(columns='state_info', inplace=True)\n",
    "dfc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - party_affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfc['party_affiliation'].value_counts()       \n",
    "\n",
    "# Obtener el conteo de valores únicos de 'speaker'\n",
    "party_affiliation_counts = dfc['party_affiliation'].value_counts()\n",
    "party_affiliation_counts_test = df_test['party_affiliation'].value_counts()\n",
    "\n",
    "\n",
    "# Convertir a diccionario\n",
    "party_affiliation_counts_dict = party_affiliation_counts.to_dict()\n",
    "party_affiliation_counts_dict_test = party_affiliation_counts_test.to_dict()\n",
    "\n",
    "# Exportar a un archivo JSON\n",
    "with open('json-study/party_affiliation_counts.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(party_affiliation_counts_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open('json-study/party_affiliation_counts_test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(party_affiliation_counts_dict, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    # Major parties\n",
    "    'republican': 'republican',\n",
    "    'democrat': 'democrat',\n",
    "    'democratic-farmer-labor': 'democrat',\n",
    "\n",
    "    # Independents / None\n",
    "    'none': 'independent_None',\n",
    "    'independent': 'independent_None',\n",
    "    'newsmaker': 'independent_None',\n",
    "    'journalist': 'independent_None',\n",
    "    'columnist': 'independent_None',\n",
    "    'activist': 'independent_None',\n",
    "    'talk-show-host': 'independent_None',\n",
    "\n",
    "    # Third parties\n",
    "    'libertarian': 'third_Party',\n",
    "    'green': 'third_Party',\n",
    "    'constitution-party': 'third_Party',\n",
    "    'liberal-party-canada': 'third_Party',\n",
    "\n",
    "    # Organizations\n",
    "    'organization': 'organization',\n",
    "    \n",
    "    # Officials  \n",
    "    'state-official': 'official',\n",
    "    'business-leader': 'official',\n",
    "    'labor-leader': 'official',\n",
    "    'education-official': 'official',\n",
    "    'government-body': 'official',\n",
    "\n",
    "    # Tea Party\n",
    "    'tea-party-member': 'republican',\n",
    "    'ocean-state-tea-party-action': 'republican',\n",
    "}\n",
    "\n",
    "def group_party(x):\n",
    "    return mapping.get(x, 'other')  # anything else → 'Other'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['party_group'] = dfc['party_affiliation'].apply(group_party)\n",
    "\n",
    "# Recuento de las nuevas categorías\n",
    "print(dfc['party_group'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.drop(columns='party_affiliation', inplace=True)\n",
    "dfc.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Create Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = df_test.copy() # Backup del dataframe original\n",
    "dfa.dtypes.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcional: Eliminar filas con valores nulos en el DataFrame 'df_test'\n",
    "# df_test = df_test.dropna()\n",
    "\n",
    "# # Mostrar la cantidad de valores nulos restantes en 'df_test'\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['statement'] = dfa['statement'].str.replace(\"Ill\", \"i'll\")\n",
    "\n",
    "dfa['statement'] = dfa.apply(lambda row: preprocess(row['statement'], row.name), axis=1)\n",
    "dfa['statement-raw']  = dfa['statement']\n",
    "dfa['statement-raw'] = dfa['statement-raw'].apply(lambda x: x.lower())\n",
    "\n",
    "# Mostrar los contadores\n",
    "print(f\"URLs eliminadas: {url_changes}\")\n",
    "print(f\"Puntuaciones eliminadas: {punct_changes}\")\n",
    "print(f\"Stopwords eliminadas: {stopword_changes}\")\n",
    "print(f\"Dígitos eliminados: {digit_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['statement-leamtize'] = dfa['statement'].apply(lambda x: lemmatize_verbs(x))\n",
    "dfa['statement-leamtize'] = dfa['statement-leamtize'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['subject'] = dfa['subject'].str.lower()\n",
    "dfa['subject_list'] = (\n",
    "    dfa['subject']\n",
    "    .str.split(',')\n",
    "    .apply(lambda lst: [s.strip() for s in lst if s.strip()])\n",
    ")\n",
    "\n",
    "# --- 2) Mapea cada subject a su categoría y quita duplicados ---\n",
    "dfa['subject_categories'] = dfa['subject_list'].apply(\n",
    "    lambda lst: list({\n",
    "        subject_mapping.get(s, 'subject-otros') \n",
    "        for s in lst\n",
    "    })\n",
    ")\n",
    "\n",
    "# (Opcional) echa un vistazo:\n",
    "print(dfa[['subject_list','subject_categories']].head())\n",
    "\n",
    "# --- 3) One-Hot Binarizer sobre la lista de categorías ---\n",
    "mlb = MultiLabelBinarizer()\n",
    "onehot = mlb.fit_transform(dfa['subject_categories'])\n",
    "\n",
    "# Construye el DataFrame de one-hot\n",
    "dfa_onehot = pd.DataFrame(\n",
    "    onehot,\n",
    "    columns=mlb.classes_,\n",
    "    index=dfa.index\n",
    ")\n",
    "\n",
    "\n",
    "dfa = pd.concat([dfa, dfa_onehot], axis=1)\n",
    "\n",
    "print(dfa.shape)\n",
    "dfa.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Agrupar los menos frecuentes como 'other_speakers'\n",
    "dfa['speaker_grouped'] = dfa['speaker'].apply(\n",
    "    lambda s: s if s in frequent_speakers else 'other_speakers'\n",
    ")\n",
    "\n",
    "dfa['speaker_grouped'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - speaker_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los menos frecuentes como 'other_speaker_jobs'\n",
    "dfa['speaker_job_grouped'] = dfa['speaker_job'].apply(\n",
    "    lambda job: job if job in frequent_speaker_jobs else 'other_speaker_jobs'\n",
    ")\n",
    "\n",
    "# Ver el resultado final\n",
    "dfa['speaker_job_grouped'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - state_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los menos frecuentes como 'other_state_info'\n",
    "dfa['state_info_grouped'] = dfa['state_info'].apply(\n",
    "    lambda info: info if info in frequent_state_info else 'other_state_info'\n",
    ")\n",
    "\n",
    "# 6. Ver el resultado final\n",
    "dfa['state_info_grouped'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - party_affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['party_group'] = dfa['party_affiliation'].apply(group_party)\n",
    "\n",
    "# Recuento de las nuevas categorías\n",
    "print(dfa['party_group'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.drop(columns='id', inplace=True)\n",
    "dfa.drop(columns='subject', inplace=True)\n",
    "dfa.drop(columns='subject_list', inplace=True)\n",
    "dfa.drop(columns='subject_categories', inplace=True)\n",
    "dfa.drop(columns='speaker', inplace=True)\n",
    "dfa.drop(columns='speaker_job', inplace=True)\n",
    "dfa.drop(columns='state_info', inplace=True)\n",
    "dfa.drop(columns='party_affiliation', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Exportar CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar los dos dataset para ver que todo esta bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar las columnas de dfc y df_testn\n",
    "columns_dfc = set(dfc.columns)\n",
    "columns_df_testn = set(dfa.columns)\n",
    "\n",
    "# Encontrar las diferencias\n",
    "differences = columns_dfc.symmetric_difference(columns_df_testn)\n",
    "\n",
    "# Verificar si la única diferencia es 'id'\n",
    "if differences == {'id', 'label'}:\n",
    "    print(\"La única diferencia entre las columnas es 'id' y 'label'.\")\n",
    "else:\n",
    "    print(\"Existen otras diferencias en las columnas:\", differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar en *formated* los csv train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el DataFrame 'dfn' a un archivo CSV\n",
    "dfc.to_csv('./formated/train_exportado.csv', index=False)\n",
    "\n",
    "dfa.to_csv('./formated/test_exportado.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Alexisbcook. (2023, 21 abril). Categorical variables. Kaggle.](https://www.kaggle.com/code/alexisbcook/categorical-variables)\n",
    "* [pandas documentation — pandas 2.2.3 documentation. (s. f.).](https://pandas.pydata.org/docs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
